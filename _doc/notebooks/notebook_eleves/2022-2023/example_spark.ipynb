{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "233e0747-98ab-4fb5-8c50-80c6a9903d6f",
   "metadata": {},
   "source": [
    "# First steps on pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e10f52-1958-494c-9f01-80d00e8f8213",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Répertoire national des élus\n",
    "https://www.data.gouv.fr/fr/datasets/repertoire-national-des-elus-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d91acaa-c8f9-402f-a786-b70d8498d840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc477efb-511e-4614-86cf-d401a26d40cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98078ff-fa51-4f0f-a8ca-f9117ef37ee4",
   "metadata": {},
   "source": [
    "## Kubernetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa32277-5022-43e8-b4cb-4ff4d4cf96c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "conf = SparkConf()\n",
    "conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591ab59-2c26-41c2-a004-102eb96e585f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!kubectl api-resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9b9aec-5a14-4692-a17e-09dc3e66a6a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!kubectl api-resources --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d613a5f1-c8bb-4b39-afa8-179686837064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021fec76-1d0d-4576-b373-d78d715b2f08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!kubectl exec sparksql-4fe7618772624ef3-exec-6 -- ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e04c2-0fc3-41bb-bc6a-460f55a0afaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!kubectl exec --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc06472-1168-46e2-bbea-8096954565c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!kubectl cluster-info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2e6d9-825e-431c-b519-f5b4527db898",
   "metadata": {},
   "source": [
    "## Dummy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b4f7e-0df4-4566-adb8-e1785836abff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e09449-ee96-4f8f-96f3-49e8353649a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile dummpy.py\n",
    "\n",
    "import random\n",
    "import string\n",
    "import datetime\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, rand, randn\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, LongType\n",
    "sparkConf = SparkConf()\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "def randomString(stringLength=10):\n",
    "    \"\"\"Generate a random string of fixed length \"\"\"\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(stringLength))\n",
    "r = randomString()\n",
    "print (\"Random String is \", r )\n",
    "path = \"/opt/spark/work-dir/\" + r\n",
    "start = datetime.datetime.now()\n",
    "print(\"spark job submitted: \" + str(start))\n",
    "dfrange = spark.range(0, 10e7+1, 1 , 32) #last value is chunk split of output file so //\n",
    "df_to_file = dfrange.select(\"id\",\n",
    "              rand(seed=5).alias(\"uniform\"),\n",
    "              randn(seed=5).alias(\"normal\"),\n",
    "              rand(seed=5).alias(\"uniform2\"),\n",
    "              randn(seed=5).alias(\"normal2\"),\n",
    "              rand(seed=5).alias(\"uniform3\"),\n",
    "              randn(seed=5).alias(\"normal3\"))\n",
    "df_to_file.write.format(\"example_spark.csv\").option(\"header\",\"true\").mode('overwrite').save(path)\n",
    "print(\"spark write finished: \" + str(datetime.datetime.now() - start))\n",
    "schema = StructType([StructField(\"id\", LongType(), True),\n",
    "                   StructField(\"field1\", DoubleType(), True),\n",
    "                   StructField(\"field2\", DoubleType(), True),\n",
    "                   StructField(\"field3\", DoubleType(), True),\n",
    "                   StructField(\"field4\", DoubleType(), True),\n",
    "                   StructField(\"field5\", DoubleType(), True),\n",
    "                   StructField(\"field6\", DoubleType(), True)])\n",
    "df_from_file = spark.read.load(path,\n",
    "                     format=\"csv\",\n",
    "                     schema=schema,\n",
    "                     header=True)\n",
    "print(\"spark read finished: \" + str(datetime.datetime.now() - start))\n",
    "df_from_file.count()\n",
    "print(\"spark count finished: \" + str(datetime.datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af15737-df2d-475a-8d85-c8276b4df48d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!spark-submit --master k8s://https://kubernetes.default.svc:443 --deploy-mode cluster \\\n",
    "        --name sparksql --conf spark.executor.instances=2 \\\n",
    "        --conf spark.kubernetes.authenticate.driver.serviceAccountName=default \\\n",
    "        --conf spark.kubernetes.namespace=default \\\n",
    "        --py-files my-pyspark-app.zip \\\n",
    "        dummy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9110000f-820c-4c0d-85bb-d0d75e35c336",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f38591-9af4-44b8-adb1-e45a6f03c3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"https://www.data.gouv.fr/fr/datasets/r/d5f400de-ae3f-4966-8cb6-a85c70c6c24a\", sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6bbef-93f9-4b77-ad55-06cc2fc7bc78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0badd2-13f6-4403-ad55-64f6162b7d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = list(map(tuple, df.itertuples()))\n",
    "setlen = set(map(len, data))\n",
    "setlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1ae66-57a9-4676-8ebc-172261e7ecfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090211ed-097f-4d0a-b48b-5c4be724576c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## From pandas to spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b099d-6667-4fbb-8812-68d247bffbef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca13d5-c751-4b2e-ae09-aa8f8c1ac0e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"sparksql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad1b0d8-c058-43e5-90db-883b8a13d282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "\n",
    "cols = [StructField(\"index\", IntegerType(), True)]\n",
    "for name, typ in zip(df.columns, df.dtypes):\n",
    "    if \"float64\" in str(typ):\n",
    "        cols.append(StructField(name, DoubleType(), True))\n",
    "    else:\n",
    "        cols.append(StructField(name, StringType(), True))\n",
    "schema = StructType(cols)\n",
    "encoded_name = schema.fields[0].name.encode('utf-8')\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fef64a-7b95-4476-b2db-5ef0a97979e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = spark.createDataFrame(data, schema=schema)\n",
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf80249d-ac8b-48ea-a003-d13f70aeb194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d167a8fb-c10e-4848-9bdf-067a2d8f0d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e445914f-6108-42f6-a58d-2e02669e8320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs.write.mode(\"overwrite\").format(\"parquet\").save(\"data/elu.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee679c5-3d75-49f1-9fe5-28c6f662279e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs.write.csv(\"data/elu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f3d4aa-b790-4a2d-a5d4-482559e12174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f65c67-a52f-4aaf-b1d5-edffd3b9d289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -ls data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb63a6-1e5d-4a63-8087-9a0df532ae40",
   "metadata": {},
   "source": [
    "## HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df90fd9-4bd0-4a4d-a974-95c612b712c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!hdfs --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27553ff-6730-457e-a05c-0fa2e1d13b85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!hdfs envvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c97bfca-1a3c-44b6-a871-fd08d134bb0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls /opt/spark/conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c197526-6778-40c7-bd24-ab0931632179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat /opt/spark/conf/spark-defaults.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e439e-9bed-4e70-98b4-df8dcafba0df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!kubectl --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e648def-a63d-4fee-a3e4-c1e4c3739b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!kubectl get pods -n spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf54e27a-c8b6-4cdb-b532-ddb151515d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!hdfs dfs --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8053d2-4717-42de-ab4c-5beae2f91c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -du"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88d041a-cf16-4b9c-9d06-d40b4c39030d",
   "metadata": {},
   "source": [
    "## Lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b73f6-c8fd-4614-a108-d6d54ba34d34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = spark.read.csv(\"data/elu.csv/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96347606-1e09-4ff0-8c0b-00b8a9e3364b",
   "metadata": {},
   "source": [
    "## Group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce6d79-307e-45be-b80d-69395eb600ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbda9c5-caea-4486-838e-cd91cd0a3b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "dfs_new = dfs.withColumn(\"année_naissance\", split(col(\"Date de naissance\"), \"/\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21812721-54ee-45ae-9a5c-e756a616757d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gr = dfs_new.groupBy(\"année_naissance\").count()\n",
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f1ca3-992b-4868-9318-c0cc2d04635a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grexe = gr.collect()\n",
    "grexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467128ca-bd8b-4d2a-b2a5-74c9a191f808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf = gr.toPandas()\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf19ed2-0875-4a6e-ac5c-55a0f538ea8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55e391-d31a-4431-b7d0-253a03ba0bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf.plot.scatter(x=\"année_naissance\", y=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3958191-60e0-4ca8-8210-85a96b090f74",
   "metadata": {},
   "source": [
    "## Mllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c43b8d-3d4f-45c3-a226-3587a0f32b28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5585c3a-0512-485d-a89d-1754bbf2aa72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669dfae-69db-4a41-bcf4-a6c8c1cae546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(10000, 10)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4104b-994f-475e-b5b3-4fa4479c5456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(X)\n",
    "df.columns = [f\"f{i}\" for i in range(len(df.columns))]\n",
    "df[\"Y\"] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad62c73-3cdb-4d5a-a9fa-9c09193e72c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = spark.createDataFrame(df.itertuples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2793d6-b23d-49cf-89b5-69b33c8adaf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a69384-d0a5-4fe5-8f32-6b5e164f90b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[f\"f{i}\" for i in range(10)], outputCol=\"features\")\n",
    "data = assembler.transform(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba419e-48d1-46f0-82dd-f333b65203b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b78a3-fad8-4b23-a4ec-3e8027075fb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression(labelCol=\"Y\", featuresCol=\"features\")\n",
    "reg_train = reg.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941f0286-4515-4233-950c-d3fdf83e8352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff88d8c-55f4-4f62-b8ad-55ca1cb794e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "predictions = reg_train.transform(testData)\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"Y\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"RMSE = {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb37c4-5a0d-4d30-aa57-922c09304d36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg_train.save(\"linreg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6efc8a7-925e-4b28-81f2-6791ab403a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -l linreg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ea834-beac-415a-94e6-33ff9be6afdb",
   "metadata": {},
   "source": [
    "## stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ea803-cb48-4f84-b84e-0c897de58556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91a9b3c-b5f4-49bb-bb9c-0451149ccde4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
